{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluation of Mistral Instruct using HuggingFace**\n",
        "\n",
        "In this notebook, we explore the evaluation of the Mistral Instruct model using HuggingFace and BeyondLLM. Evaluation is essential for understanding how well a model performs on various tasks and its ability to generate relevant responses.\n",
        "\n",
        "- **Objective:** Assess the Mistral Instruct model's performance using context relevancy, answer relevancy, and groundedness metrics.\n",
        "- **Setup:**\n",
        "  - Configure the retrieval pipeline for data processing.\n",
        "  - Use HuggingFace and BeyondLLM for model integration.\n",
        "- **Steps:**\n",
        "  - Load and preprocess data.\n",
        "  - Initialize the Mistral Instruct model and retrieval system.\n",
        "  - Generate responses to sample queries.\n",
        "  - Evaluate the responses using defined metrics.\n",
        "- **Outcome:** Gain insights into the model’s effectiveness and areas for improvement in understanding and generating responses based on the given data.\n",
        "\n",
        "\n",
        "## Setup and Installation\n",
        "\n",
        "First, let's install the necessary packages:"
      ],
      "metadata": {
        "id": "ZlPqyPD47rG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beyondllm==0.2.2\n",
        "!pip install huggingface_hub==0.20.1\n",
        "!pip install llama-index-embeddings-fastembed==0.1.3"
      ],
      "metadata": {
        "id": "I1WvikA17uvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's import the required libraries and set up our environment:"
      ],
      "metadata": {
        "id": "G7-Gawhp7_1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from beyondllm.source import fit\n",
        "from beyondllm.embeddings import FastEmbedEmbeddings\n",
        "from beyondllm.retrieve import auto_retriever\n",
        "from beyondllm.llms import HuggingFaceHubModel\n",
        "from beyondllm.generator import Generate\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Set up HuggingFace API token\n",
        "os.environ['HUGGINGFACE_ACCESS_TOKEN'] = getpass(\"Enter your HF API token:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "827aVCn4798Q",
        "outputId": "d45ab4cb-c0bc-4126-c7a2-3aba564fd2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /usr/local/lib/python3.10/dist-\n",
            "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your HF API token:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Model Configuration\n",
        "\n",
        "Let's load our data and configure the embedding model:"
      ],
      "metadata": {
        "id": "gNPIqciU8iui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the PDF data\n",
        "data = fit(\"/content/Shivaya Resume.pdf\", dtype=\"pdf\")\n",
        "\n",
        "# Initialize the embedding model\n",
        "embed_model = FastEmbedEmbeddings()\n",
        "\n",
        "# Set up the retriever\n",
        "retriever = auto_retriever(data=data, embed_model=embed_model, type=\"normal\", top_k=3)\n",
        "\n",
        "# Initialize the Mistral Instruct model\n",
        "llm = HuggingFaceHubModel(model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ2f2WMR8kKN",
        "outputId": "113b94fc-c5bf-49b0-e720-4632737417f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76.7M/76.7M [00:01<00:00, 68.0MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Response and Evaluate\n",
        "\n",
        "Now, let's generate a response to a question and evaluate the model's performance:\n"
      ],
      "metadata": {
        "id": "TYaXTCGc9Cvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the generation pipeline\n",
        "pipeline = Generate(question=\"What are her hobbies?\", llm=llm, retriever=retriever)\n",
        "\n",
        "# Generate the response\n",
        "response = pipeline.call()\n",
        "print(\"AI Response:\")\n",
        "print(response)\n",
        "\n",
        "# Get evaluation metrics\n",
        "eval_metrics = pipeline.get_rag_triad_evals()\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(eval_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHXRNzQs9FQq",
        "outputId": "fa6edd7b-8d2c-4dca-d06a-f4a2c90f3a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Response:\n",
            "\n",
            "        ANSWER: Based on the provided context, Shivaya Pandey has shown interest and expertise in various areas related to Computer Science, Data Science, and Artificial Intelligence. Some of the projects mentioned in her portfolio include a Heart Disease Prediction System, Sign Language Detector, Video Text Overlay Tool, and Gold Price Prediction Model. These projects suggest that she enjoys working with Python, machine learning, and developing innovative solutions. Additionally, she has experience in coding in Java, C, and C++. Furthermore, she has published tech articles on Medium and is certified in Python programming. Therefore, her hobbies can be inferred to be related to computer science, data science, artificial intelligence, and writing.\n",
            "Executing RAG Triad Evaluations...\n",
            "\n",
            "Evaluation Metrics:\n",
            "Context relevancy Score: 3.5\n",
            "This response does not meet the evaluation threshold. Consider refining the structure and content for better clarity and effectiveness.\n",
            "Answer relevancy Score: 10.0\n",
            "This response meets the evaluation threshold. It demonstrates strong comprehension and coherence.\n",
            "Groundness score: 9.5\n",
            "This response meets the evaluation threshold. It demonstrates strong comprehension and coherence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we demonstrated how to evaluate the Mistral Instruct model using HuggingFace and BeyondLLM. We set up a retrieval pipeline, generated a response to a specific question, and obtained evaluation metrics for context relevancy, answer relevancy, and groundedness.\n",
        "\n",
        "This approach allows us to assess the model's performance in understanding context, providing relevant answers, and ensuring the responses are grounded in the provided information. Such evaluation is crucial for improving and fine-tuning language models for specific tasks or domains.\n",
        "\n",
        "Feel free to experiment with different questions, datasets, or model parameters to further explore the capabilities of the Mistral Instruct model."
      ],
      "metadata": {
        "id": "SYOIF_pB9bBp"
      }
    }
  ]
}